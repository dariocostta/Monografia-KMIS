{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ace2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "from bibkmis.auxkmis import *\n",
    "from bibkmis.typeskmis import SOLUCAO, KMIS\n",
    "\n",
    "import ast                      # Ler os litearias de tipos simples\n",
    "import os                       # Controle de pastas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np              # Principal para ferramentas matematicas\n",
    "from tqdm import tqdm           # Barrinha de progresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ec5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura de instancias.csv (540 linhas) bem sucedida.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstruindo Instâncias: 100%|██████████| 540/540 [00:02<00:00, 211.59it/s] \n"
     ]
    }
   ],
   "source": [
    "# Restaurando Instâncias para consulta\n",
    "dictI = {\n",
    "  \"id\": [], \"kmis\": [], \"p\": [], \"k\": [],\n",
    "  \"|L|\": [], \"|R|\": [], \"L\": [], 'temSol': [], 'classe': []\n",
    "}\n",
    "dfI = pd.DataFrame(columns = list(dictI.keys()))\n",
    "# ==== Carregamento de Instâncias Salvas =====\n",
    "conv = {\n",
    "  'L'     : ast.literal_eval,\n",
    "  'temSol': ast.literal_eval,\n",
    "  'L_b14' : ast.literal_eval,\n",
    "  'Llabel': ast.literal_eval,\n",
    "  'Rlabel': ast.literal_eval\n",
    "}\n",
    "try:\n",
    "  dfI = pd.read_csv('instancias.csv', converters=conv)\n",
    "  print(f'Leitura de instancias.csv ({dfI.shape[0]} linhas) bem sucedida.')\n",
    "except:\n",
    "  print('\\n\\n\\t\\tArquivo instancias não encontrado!!\\n\\n')\n",
    "  assert dfI.shape[0]>0 , \"Sem instâncias não continua! Peque o arquivo 'instancias.csv'.\"\n",
    "\n",
    "# Reinstanciar objetos KMIS a partir das linhas do CSV\n",
    "dictI['kmis_b14'] = []\n",
    "with tqdm(total = dfI.shape[0], smoothing = 0.001, desc=\"Reconstruindo Instâncias\") as pbar:\n",
    "  for _, row in dfI.iterrows():\n",
    "    kmis = KMIS(row['|L|'], row['|R|'], row['p'], row['k'], row['L'])\n",
    "    kmis_reduzido = KMIS(row['|L|_b14'], row['|R|_b14'], row['p'], row['k'], row['L_b14'])\n",
    "    kmis_reduzido.Llabel = row['Llabel_b14']\n",
    "    kmis_reduzido.Rlabel = row['Rlabel_b14']\n",
    "    dictI['kmis'].append(kmis)\n",
    "    dictI['kmis_b14'].append(kmis_reduzido)\n",
    "    pbar.update(1)\n",
    "\n",
    "dfI['kmis'] = dictI['kmis']\n",
    "dfI['kmis_b14'] = dictI['kmis_b14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura das tabelas:\n",
    "try:\n",
    "  dfAT = pd.read_csv('teste_parametros.csv')\n",
    "  dfRT = pd.read_csv('resultados.csv')\n",
    "  dfIRT = pd.read_csv('resultados_reduzidas.csv')\n",
    "except:\n",
    "  print('Tem arquivo faltante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Analise dos resultados geral\"\"\"\n",
    "\n",
    "# ===========================================================================================\n",
    "assert isinstance(dfRT, pd.DataFrame), '\\t ⚠️ DataFrame do teste final não definido.'\n",
    "dfR_hi = dfRT.groupby(['idH', 'idI'])[['val', 'time']].apply(junta_repeticoes).reset_index()\n",
    "dfR_h  = dfR_hi.groupby(['idH'])[['vmin', 'vavg', 'vmax', 'tavg']].apply(medias).reset_index()\n",
    "dfR_i  = dfR_hi.groupby(['idI'])[['vmin', 'vavg', 'vmax', 'tavg']].apply(melhor_por_instancia).reset_index()\n",
    "# Comparações\n",
    "cmp = dfR_hi.merge(dfR_i, on=['idI'])\n",
    "cmp['eq_vmin'] = cmp['vmin'] == cmp['vmin_max']\n",
    "cmp['eq_vmax'] = cmp['vmax'] == cmp['vmax_max']\n",
    "cmp['eq_vavg'] = np.isclose(cmp['vavg'], cmp['vavg_max'], atol=1e-4)\n",
    "cmp['eq_tavg'] = np.isclose(cmp['tavg'], cmp['tavg_min'], atol=1e-4)\n",
    "\n",
    "# Contagem e merge final\n",
    "cnt = cmp.groupby(['idH'])[['eq_vmin', 'eq_vavg', 'eq_vmax', 'eq_tavg']].sum().rename(columns=lambda c: 'cnt_' + c[3:]).reset_index()\n",
    "dfR = dfR_h.merge(cnt, on=['idH'])\n",
    "df_limites = limites_argumento(dfR).to_frame().T\n",
    "df_score = dfR.merge(df_limites, how='cross')\n",
    "dfR['score'] = df_score.apply(score_time_off, axis=1)\n",
    "\n",
    "dfR.to_csv('resultados_avaliados_geral.csv', index = False)\n",
    "print(dfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad57cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Analise dos resultados por classe\"\"\"\n",
    "# ===========================================================================================\n",
    "dfRT_c = dfRT.merge(dfI[['id', 'classe']], left_on='idI', right_on='id').drop('id', axis=1)\n",
    "dfR_hi = dfRT_c.groupby(['classe', 'idH', 'idI'])[['val', 'time']].apply(junta_repeticoes).reset_index()\n",
    "dfR_i  = dfR_hi.groupby(['idI'])[['vmin', 'vavg', 'vmax', 'tavg']].apply(melhor_por_instancia).reset_index()\n",
    "dfR_h_c  = dfR_hi.groupby(['classe','idH'])[['vmin', 'vavg', 'vmax', 'tavg']].apply(medias).reset_index()\n",
    "cmp = dfR_hi.merge(dfR_i, on=['idI'])\n",
    "cmp['eq_vmin'] = cmp['vmin'] == cmp['vmin_max']\n",
    "cmp['eq_vmax'] = cmp['vmax'] == cmp['vmax_max']\n",
    "cmp['eq_vavg'] = np.isclose(cmp['vavg'], cmp['vavg_max'], atol=1e-4)\n",
    "cmp['eq_tavg'] = np.isclose(cmp['tavg'], cmp['tavg_min'], atol=1e-4)\n",
    "cnt = cmp.groupby(['classe', 'idH'])[['eq_vmin', 'eq_vavg', 'eq_vmax', 'eq_tavg']].sum().rename(columns=lambda c: 'cnt_' + c[3:]).reset_index()\n",
    "dfR_c = dfR_h_c.merge(cnt, on=['classe', 'idH'])\n",
    "df_limites = dfR_c.groupby(['classe'])[dfR_c.columns[2:]].apply(limites_argumento)\n",
    "df_score = dfR_c.merge(df_limites, left_on='classe', right_index=True)\n",
    "dfR_c['score'] = df_score.apply(score_time_off, axis=1)\n",
    "\n",
    "Score_PerClass = pd.DataFrame({'idH':dfR_c['idH'].unique()})\n",
    "for i in dfR_c['classe'].unique():\n",
    "  subset = pd.DataFrame(dfR_c[dfR_c['classe'] == i][['classe', 'idH', 'score']])\n",
    "  subset = subset.rename(columns = {'score':f'score_{i}'})\n",
    "  # display(subset)\n",
    "  Score_PerClass = Score_PerClass.merge(subset, on='idH', how='left').drop('classe',axis=1)\n",
    "# Score_PerClass = Score_PerClass.drop(['score_C2','score_C6'], axis=1)\n",
    "Score_PerClass['avg'] = Score_PerClass.apply(lambda x: x[1:].mean(), axis=1)\n",
    "Score_PerClass.to_csv('resultados_avaliados_por_classe.csv', index = False)\n",
    "print(Score_PerClass.sort_values('avg', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
